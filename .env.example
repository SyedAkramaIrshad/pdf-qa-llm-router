# Z.ai GLM API Configuration
GLM_API_KEY=your_api_key_here
GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4/

# Using FREE models (no billing required)
GLM_MODEL=glm-4.5-flash
GLM_VISION_MODEL=glm-4.6v-flash

# Processing Configuration
CHUNK_SIZE=10                    # Pages per section
MAX_CONCURRENT_CALLS=3           # Lite plan has ~3 concurrent limit
MAX_RETRY_ATTEMPTS=3             # Max retry for error correction

# Indexing Configuration (DEFAULT: SEQUENTIAL for quality)
INDEXING_CONCURRENT=1            # 1 = sequential (safe), >1 = parallel (may rate limit)
API_DELAY=1.0                    # Seconds delay between API calls

# Logging
LOG_LEVEL=INFO
